import Foundation
import Testing
@testable import MyTranslation

struct SentinelEncodingTests {
    @Test
    func sentinelEncodingRoundTripIsIdempotent() {
        let original = "ê·¸ê°€ __ENT#41__ì„ ì°¾ì•˜ë‹¤. \"__ENT#10__\"ë„ ë´¤ë‹¤."
        let encoded = encodeSentinels(original)
        #expect(encoded == "ê·¸ê°€ ğŸŸ§ENT41ğŸŸ§ì„ ì°¾ì•˜ë‹¤. \"ğŸŸ§ENT10ğŸŸ§\"ë„ ë´¤ë‹¤.")
        #expect(encodeSentinels(encoded) == encoded)

        let decoded = decodeSentinels(encoded)
        #expect(decoded == original)
        #expect(decodeSentinels(decoded) == decoded)
    }

    @Test
    func sentinelEncodingKeepsAdjacentTokensTight() {
        let original = "__ENT#4____ENT#5__"
        let encoded = encodeSentinels(original)
        #expect(encoded == "ğŸŸ§ENT4ğŸŸ§ğŸŸ§ENT5ğŸŸ§")

        let decoded = decodeSentinels(encoded)
        #expect(decoded == original)
    }

    @Test
    func sentinelEncodingPreservesZeroWidthCharacters() {
        let zwsp = "\u{200B}"
        let original = "__ENT#21__\(zwsp)ì€ \"__ENT#10__\"ê³¼"
        let encoded = encodeSentinels(original)
        #expect(encoded == "ğŸŸ§ENT21ğŸŸ§\(zwsp)ì€ \"ğŸŸ§ENT10ğŸŸ§\"ê³¼")

        let decoded = decodeSentinels(encoded)
        #expect(decoded == original)
    }

    @Test
    func sentinelEncodingIgnoresDamagedTokensUntilNormalization() {
        let original = "ENT#7__ ê³¼ __ENT#8"
        let encoded = encodeSentinels(original)
        #expect(encoded == original)

        let masker = TermMasker()
        let normalized = masker.normalizeDamagedTokens(encoded)
        #expect(normalized == "__ENT#7__ ê³¼ __ENT#8__")
    }

    @Test
    func sentinelPipelineProtectsTokensAndPreservesContext() {
        let masker = TermMasker()
        let locks: [String: LockInfo] = [
            "__ENT#21__": LockInfo(
                placeholder: "__ENT#21__",
                target: "ì´ˆí•©ê¸ˆ",
                endsWithBatchim: true,
                endsWithRieul: false,
                category: .term
            ),
            "__ENT#10__": LockInfo(
                placeholder: "__ENT#10__",
                target: "ë¹›",
                endsWithBatchim: true,
                endsWithRieul: false,
                category: .term
            )
        ]

        let original = "__ENT#21__ì€ \"__ENT#10__\"ê³¼ í•¨ê»˜ ì›€ì§ì˜€ë‹¤."
        let encoded = encodeSentinels(original)
        #expect(encoded == "ğŸŸ§ENT21ğŸŸ§ì€ \"ğŸŸ§ENT10ğŸŸ§\"ê³¼ í•¨ê»˜ ì›€ì§ì˜€ë‹¤.")

        let simulatedTranslationOutput = encoded
        let decoded = decodeSentinels(simulatedTranslationOutput)
        #expect(decoded == original)

        var restored = masker.normalizeDamagedTokens(decoded)
        restored = masker.normalizeEntitiesAndParticles(
            in: restored,
            locksByToken: locks,
            names: [],
            mode: .tokensOnly
        )
        let unlocked = masker.unlockTermsSafely(restored, locks: locks)

        #expect(unlocked == "ì´ˆí•©ê¸ˆì€ \"ë¹›\"ê³¼ í•¨ê»˜ ì›€ì§ì˜€ë‹¤.")
    }
}
